---
title: "Biostatstic in R"
author: "George Wiggins"
date: "11/12/2020"
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    number_sections: false
    theme: lumen
    css: www/css/master.css
    highlight: default
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, fig.align = 'center')
```


# Introduction


## Datasets

To illustrate some commonly statistical procedures in biology a few near-real world dataset will be used.  

### Knockdown of candidate gene
This dataset is based on the hypothesis that the deletion of a gene (geneX) will alter the growth of endometrial cancer cells. To test this, two cell lines (AN3CA and EM-E6/E7-hTERT) were transfected with one of three siRNA, all targeting geneX. After transfection, proliferation (cell metabolism) of each experimental condition was measured by a MTT assay. These experiments were repeated in triplicate across three weeks.

### Chick weights on different diets
This is a dataset that is avaliable through an R package `chickwts` that measure the weight of different chicks on different feeds. 

### Novel therapies: blood haemoglobin
This is a hypothetical dataset made to compare several treatments to standards care. The change in blood haemoglobin from baseline was recorded for 10 individuals randomly assigned to either standard care or one of six novel therapies (named DrugA-DrugF).

# R 
This is a desgined to be a simple guide to performing statistical analysis in R. There will be some statistical theory but the purpose is to show how statistical tests can be executed in R and how to display these results. 

For those not familiar with R, R is a statistical language which is useful for more complex statistical procedures and presenting data. For the most part, this guide will have provide simple examples and "how-tos". A major challenge is often "wrangling" data into a format so that a function can be executed. For data wrangling, I will try use the latest `tidyverse` syntax. Alternatively, it is possible to 'wrangle'/organise data in excel before importing into R.

## To start
I recommend installing [RStudio Desktop](https://www.rstudio.com/products/rstudio/download/), a IDE (integrated development environment) for R that allows a more user friendly experience of R. If you prefer writing in a console, then you can install [R](https://www.r-project.org/). 

Here are some packages that are used to generate this file, some may need to be installed through CRAN using the `install.packages()` function, github using the `install_github()` function from `devtools` or bioconductor using `install()` from the `BiocManager` package.

```{r datasets, results='hide',error=FALSE, warning=FALSE, message=FALSE}
## Read excelsheets
library(openxlsx)

## Packages used for 'data wrangling'
library(tidyverse)
library(data.table)

## Extra stats package
library(rstatix) ## used to help format stats into dfs for ggplot
library(DescTools) ## For Dunnett's test

## Packages for plotting and table outputs
library(ggplot2)
library(ggsci)
library(ggpubr)
library(cowplot)
library(kableExtra) ## used for to make nicer looking tables
```

### Tidyverse syntax
Tidyverse (`tidyr`, `dpylr`) has a unique syntax/funcationality compared to base R that allows the output of one function to be 'piped' into a second function. Piping is implemented with by the pipe function (`%>%`). As a simple explaination, lets assume a user whats to exclude rows based on some term and then summarise that data. This can be achieved by piping, or by storing the ouputs of each function, I'll use the mtcars dataset to demonstrate. 
```{r tidyr}
## Tidyverse with piping
group_by(mtcars, cyl) %>% filter(cyl != 4) %>% summarise(mean=mean(mpg))
```

```{r baseR}
## No piping
x <- group_by(mtcars, cyl)
y <- filter(x, cyl !=4)
summarise(y, mean=mean(mpg))
```

Note: The function I used are all from the tidyverse world, this just illustrates the piping function that will be use regularly throughout the document.



```{r global_functions, echo=FALSE}
bxplot <- function(...){ggplot(...)+geom_boxplot(width=0.4, size=1, fatten=1, colour="grey70") +
  geom_point(colour="steelblue", size=1.2, alpha=0.5) +
  theme_bw(base_size=14)}

p.siginf<- function(vec){
  out<-c()
  for(i in 1:length(vec)){
    if(vec[i] < 0.001){
      out <- c(out, "***")
    }else if( vec[i] < 0.01){
      out <- c(out, "**")
    } else if(vec[i] <0.05){
      out <- c(out, "*")
    }else{
      out <- c(out, "ns")
    }
  }     
  return(out)
}
```

**Load data**

R can phrase several file types, the easiest are flat files (e.g. tab-delimited text files or comma-separated values files). I have uploaded several files to a github which you can download and import them into R. As most experimental data collected is often stored in excel, I have used a package `openxlsx` which has the ability to read individual excel sheets. 


```{r ReadData}
## Ensure the path to data is correct
sheetNames<-getSheetNames("Data/DummyData_MTT.xlsx") ## Gives you a list of sheetNames in a given excel workbook

## Read a single sheet (the first sheet) from a workbook 
# for details on function type ?function (e.g. ?read.xlsx)
Exp1 <- read.xlsx("Data/DummyData_MTT.xlsx", sheet=sheetNames[1]) # [1] denotes which sheet to read in

## Read all the sheets and store as a list
KD_data<-lapply(sheetNames,function(i) read.xlsx("Data/DummyData_MTT.xlsx", sheet=i))
names(KD_data) <- c(paste("Exp",1:3, sep=""), 'normalised')
```


<br>
<hr>

# What is your N?
If inferences on the populations are to be made, then the number of independent biological units is your sample size (n). This should not be confused with technical replicates, which are used to capture technical variability. 

Take the knockdown of geneX as an example:  

For the each cell line there are six experiment conditions with 3 technical replicates, this counts as one biological replicate. Note the standard deviation (sd) describes the variance of the experimental conditions.  

```{r KDdata, warning=F}
## select from a list the second experiment and limit it to one cell (AN3CAs)
## Also remove the column the labels cells
dat <- KD_data %>% `[[`('Exp2') %>% filter(cellLine == "AN3CA") %>% select(!cellLine)

## Add column-wise means and sd
dat <- rbind(dat,colMeans(dat[1:6]))
dat<- rbind(dat,apply(dat[,1:6],2,sd))
rownames(dat) <- c(paste("Rep",1:3, sep=""), "mean", "sd")

## Format for output in the html document. 
dat %>% kbl(digit=3, format='html',caption = "Abs570nm (minus blanks) for a single experiment", table.attr =  'style= "width: 70%;"') %>% kable_classic( html_font = "Cambria", font_size=16)  %>% row_spec(3, extra_css = "border-bottom: 1px solid")
```

The above was repeated on three independent passages of cells, this is the number biological replicates (i.e. the n).  

<div style= "float:right;position: relative; padding-left: 25px; padding-right: 10px;padding-top: 10px">

```{r KDdataExp, echo=F,warning=F, comment=F,  message=F, fig.width=6, fig.height=4, fig.cap = "Assessment of cell viability by MTT assay for three indepedent replicates across two cell lines. Quantitative analysis of MTT is represented as the mean +/- SD of three technical replicates"}
KD_all_exp <- KD_data # copy to prevent overwriting
KD_all_exp[['normalised']] <- NULL  # remove the normalised dataframe from the list

## Bind all expreiments together, caluculate the means and sd and plot
rbindlist(KD_all_exp, idcol = T) %>% pivot_longer(2:7)%>% group_by(cellLine, name,.id) %>% summarise(mean=mean(value), sd = sd(value))%>% ggplot(aes(name, mean)) +geom_errorbar(aes(x=name, ymin=mean-sd, ymax=mean+sd), width=.2)+ geom_col(width=.7) + facet_grid(.id~cellLine) +theme_bw(base_size = 10)+ylab("A560-A670") +xlab(NULL)+theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

</div>

```{r KDdataSummary, echo=F,warning=F, comment=F,  message=F}
## Select the normalised data summarise and format for plotting
KD_data %>% `[[`('normalised') %>% pivot_longer(1:6) %>% group_by(cellLine, name)%>% summarise(mean=mean(value), sd = sd(value), n=n()) %>% filter(name != "CellsOnly") %>% kbl(digit=3, format = 'html', caption = "MTT assay normalised to untreated WT", table.attr =  'style= "margin-top: 60px;margin-bottom: 60px;text-align:center; width: 50%;"') %>% kable_classic(html_font = "Cambria", font_size=16)

```
<p class="clear">
</p>

### References
[Lazic SE, Clarke-Williams CJ, Munafo MR. Plos one (2018).](https://doi.org/10.1371/journal.pbio.2005282)

<hr>

# SD, SE and CI
It is important to display the variability around the data reported, it is important to know what is appropriate to report.  
Simply, it depends on whether you what to describe the spread of the data or the precision of the means.

If concerned with describing the variability of data then the **standard deviation** is the method of choice. When data is normally disturbed 68% of the data falls within the 1st standard deviation. 

```{r normalDist, warning=F, echo=F, fig.cap="Relationship of standard deviation and normal distrubtions", fig.height=3}
par(mar=c(3,3,2,1))
x<-rnorm(10)
plot(seq(-3.2,3.2,length=50),dnorm(seq(-3,3,length=50),0,1),type="l",xlab="",ylab="",ylim=c(0,0.5))
segments(x0 = c(-3,3),y0 = c(-1,-1),x1 = c(-3,3),y1=c(1,1))
text(x=0,y=0.45,labels = expression("99.7% of the data within 3" ~ sigma),cex=0.8)
arrows(x0=c(-2,2),y0=c(0.45,0.45),x1=c(-3,3),y1=c(0.45,0.45))
segments(x0 = c(-2,2),y0 = c(-1,-1),x1 = c(-2,2),y1=c(0.4,0.4))
text(x=0,y=0.3,labels = expression("95% of the data within 2" ~ sigma), cex=0.8)
arrows(x0=c(-1.5,1.5),y0=c(0.3,0.3),x1=c(-2,2),y1=c(0.3,0.3))
segments(x0 = c(-1,1),y0 = c(-1,-1),x1 = c(-1,1),y1=c(0.25,0.25))
text(x=0,y=0.15,labels = expression("68% of the data within 1" * sigma),cex=0.8)

```

Therefore, given the data from one experiment (i.e. one biological replicate), it is possible to display the data as mean +/- standard deviation. This provides information about how 'tight' your data is around the mean. It does not give any inference on how well the mean of the sample represents the true mean. For that we need to increase the number of replicates.

```{r exp2, warning=F, echo=F, fig.cap="Assessment of cell viability by MTT assay for one experiment. Quantitative analysis of MTT represented as the mean +/- SD of three techical replicates",  fig.height=3}
dat[1:3,] %>% pivot_longer(1:6) %>% group_by(name)%>%summarise(mean=mean(value), sd=sd(value)) %>% 
  ggplot(aes(name,mean)) + geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width =.2)+ ylab("A560nm - A670nm") + xlab(NULL)+
  geom_col(width=.5) + geom_text(aes(label=signif(mean, digits=2)), nudge_y = -0.05, color='white')+ theme_bw()
```

Research is often concerned with differences between experimental groups, therefore, it is critical to determine the level of confidence in you samples means. The **standard error** provides the accuracy of a sample mean by measuring the sample-to-sample variability of the sample mean. It is calculated by taking the standard deviation of sample mean divided by square root of number of samples. 
$$SE= \frac{\sigma}{\sqrt{n}}$$
**EXAMPLE**  
To inspect the effect of genex knockdown on proliferation on two cell lines, we can measure the proliferation of cell post-siRNA-transfection. This is repeated in three independent experiments and we can evaluate the mean of means (e.g. the means of each experiments).  
*Note: For this analysis, I have normalised each experiment to an untreated (cells only) control (e.g. $x=OD_{sample}/OD_{cellOnly}$).*

```{r SEM, echo=F,fig.cap="A) Individual data points for each experiment colored by experimental condition. B) Assessment of cell viability by MTT assay. Quantitative analysis of MTT represented as the mean +/- SE for three replicates realtive to untreated cells.",  fig.height=6, fig.width=10, message=F}

x <- KD_data
x[['normalised']] <- NULL
p1<-rbindlist(x, idcol = T) %>% pivot_longer(2:7) %>% filter(name != "CellsOnly")%>%
  ggplot(aes(.id, value, col = name)) + geom_point(size=2) +coord_flip()+ theme_bw()+ scale_color_npg() +
  theme(legend.position = 'top') + ylab(NULL)+ xlab(NULL) + facet_wrap(~cellLine, nrow = 2, scales="free") +theme(legend.title = element_blank())



p2<-KD_data %>% `[[`('normalised') %>% pivot_longer(1:6) %>% filter(name != "CellsOnly") %>% 
  add_column(y = 0) %>% mutate(names=name) %>% unite(label, name,Exp, sep="_") %>%
  ggplot(aes(x = value, y = y, label = label, col = names)) + 
  geom_point() + theme_classic()+ xlab(NULL)+
  geom_text(hjust = 'left', angle = 90, size = 4.5, nudge_y = .001) +
  ylim(0, 0.05) +theme(axis.title.y =element_blank(),
                      axis.text.y = element_blank(),
                      axis.ticks.y=element_blank(),
                      axis.line = element_blank(),
                      legend.position = "none") +
  geom_hline(yintercept = 0) + facet_wrap(~cellLine, scales = 'free') + scale_color_npg()

left<-plot_grid(p1,p2, rel_heights = c(1.6,1), nrow=2 ,labels=c("A", "B"), align = 'h', axis='t')

p3<-KD_data %>% `[[`('normalised') %>% pivot_longer(1:6) %>% 
  group_by(cellLine, name)%>% summarise(mean=mean(value), sd = sd(value), n=n(), se = sd(value)/sqrt(n())) %>% filter(name != "CellsOnly") %>%
  ggplot(aes(name, mean)) + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width =.2)+ ylab("Relative cell proliferation") + xlab(NULL)+
  geom_col(width=.7) + geom_text(aes(label=round(mean, digits=2), size=1.25), nudge_y = -0.1, color='white', size=3)+ theme_bw() +facet_wrap(~cellLine)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=10))

#plot_grid(left,p3, ncol=2, labels=c("","C"))
plot_grid(p1 +theme(legend.position = 'right'),p3 , ncol=1, labels = LETTERS[1:2], axis = 'lr', align='v', rel_widths = c(1.3,1))

```


Similar to the standard error the **confidence interval** is the as estimate of how accurately the sample mean represents the true mean. A 95% confidence interval describes the range in which you can be 95% confident that the true population mean exists. If the sample size is sufficeint (n > 30, i.e. when central limit therom applies) or population standard deviation is known than the $Z$-value can be used compute the CI:
$$CI=\bar{x}\pm{}Z\frac{s}{\sqrt{n}} $$
Where, $\bar{x}$ is the mean, $Z$ is the chosen Z-value (for 95% CI $Z$=1.96), $s$ is the sample standard deviation and $n$ is the sample size.  

```{r CI-Zscore, echo=F}
zScore <- data.frame(CI= c(90,95,99), Z=c(1.645, 1.96,2.576))

zScore %>% kbl(format = 'html', caption = "Z-value for commonly used CI", table.attr =  'style= "text-align:center; width: 30%;"') %>% kable_classic(html_font = "Cambria", font_size=16)
```
For when sample size is too small, CI should be estimated from a t-distrubtion. 
$$CI=\bar{x}\pm{}t_{n-1}\frac{s}{\sqrt{n}} $$
Where, $\bar{x}$ is the mean, $t_{n-1}$ is the taken from the t-distrubtion based on df ($n-1$) and on give probability ($\alpha$), $s$ is the sample standard deviation and $n$ is the sample size. The t-value can be calculate in R with with the `qt()` function. For example, for 95% CI and 10 samples the t value `qt(.95 + (1-.95)/2, df=10-1)`


```{r CI-tscore, echo=F}
tScore <- data.frame(df= c(2,3,4,5,8,10,20,50,100), 
                     CI95=c(4.303, 3.182, 2.776, 2.571, 2.306, 2.228, 2.086, 2.009, 1.984), 
                     CI99= c(9.925,5.841,4.604,4.032, 3.355, 3.169, 2.845, 2.678, 2.626))

tScore %>% kbl(format = 'html', caption = "t-table for some commonly used df", table.attr =  'style= " width: 40%;"', col.names = c('df',"95%", "99%")) %>% kable_classic(html_font = "Cambria", font_size=16) %>% footnote(general = "df=n-1", general_title = "", escape = F)
```
### Reference

[Error bars in experimental biology](https://dx.doi.org/10.1083%2Fjcb.200611141)

# t test

**What is a t-test?**

Simply, it is a test that determines whether the difference between group means could happen by chance. Mathematically, it attempts to reject the null hypothesis that two distributions are equal ($H_0: \mu_1 = \mu_2$). This is important, as a p-value that fails to reject the null hypothesis, does not accept the null. That is, a p > $\alpha$ (critical value) does not mean the population distributions are equal.

**How to calculate a t-test?**

Excel (T.TEST), prism and R (`t.test()`) all have in-built functions which are best to use, assuming you use the correct parameters. However, it might be useful to understand what is being calculated.
A test ($t$) statistic is computed by calculating the ratio of difference between two groups over the differences within groups. For example the Welch t-test is: $$t= \frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{s^{2}_{1}}{N_1}+\frac{s^{2}_{2}}{N_{2}}}}$$
Where, $\bar{x}_1$ and $\bar{x}_2$ are the means of two groups and $s_1$and $s_2$ are the respective standard errors. Therefore, a larger $t$-statistic describes a greater difference between populations than within a population and more likely there is a true difference. A p-value is the probability that the data occurred by chance. Given a $t$-statistic and the degrees of freedom ($N-1$), the p-value can be calculated. It is dependent on the null hypothesis, as an example the p-value for a give t-statistic is the area under the curve.


````{r t-dist, echo=F, fig.height=3.5, fig.width=8.5 , fig.align='center', fig.cap="Effects of degrees of freedom (left) and an example of one-tailed test (right)."}
par(mfrow=c(1,2), mar=c(4,4,4,1))

x <- seq(-4, 4, length=1000)
hx <- dnorm(x)

degf <- c(1, 2, 5, 10)
colors <- c("red", "blue", "darkgreen", "gold", "black")
labels <- c("df=1", "df=2", "df=5", "df=10", "normal")

t.value <- 2.12

plot(x, hx, type="l", lty=1, lwd=2, xlab="t statistic",
     ylab="Density", main="Comparison of t Distributions")

for (i in 1:4){
    lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}
legend("topright", title="Distributions",
       labels, lwd=1.5, lty=c(1, 1, 1, 1, 1), col=colors, cex=0.75)

hy <-dt(x,df=9)
p <- round(pt(t.value, 9, lower=F), 3)
plot(x,hy, type='l', lwd=3, main=expression(paste(bolditalic("p"), bold("-value for "),bolditalic("T = 2.12, df = 9"))),
     xlab="t statistic", ylab="Density", yaxs='i', ylim=c(min(hy),.4))
polygon(c(x[x>=t.value], t.value), c(hy[x>=t.value], hy[x==max(x)]), col = '#52accc')
abline(v=t.value, lty=2, col='#455a64')
#text(x=t.value*1.15, y= min(hy)*3, label=t.value, cex=.8)
mtext(t.value, at =t.value+0.3, side=1,line=0, cex=.75)
text(x=t.value*1.45, y= max(hy)*.95, label= paste("p = ", p), cex=0.75)
```

The t-statistic can then be compared to a cumulative probability to see if this rejects the null hypothesis. Take the distributions above, if a two-tailed test is calculated then if you score is at the extremes then it rejects the null hypothesis.

**EXAMPLE**  
To test if there is a change in cell viability due to the knockdown of geneX in each cell line, we can preform a $t$-test on each of the relevant comparisons. The simplest method in R, is to use the `t.test()` function which can take two vectors or you can pass in your data as formula (with the syntax of `value~group`).   

```{r tTest}
## Select the nomalised data and remove the cellsOnly data, limit to AN3CAs only.
test_data<- KD_data %>% `[[`('normalised') %>% pivot_longer(1:6) %>% filter(name != "CellsOnly", cellLine == "AN3CA") 

## t.test: Scramble treated vs siRNA1 treated cells
## as an example the t.test using the formula is written below but commented out
# values.both <- test_data %>% filter(name%in%c("siRNA1","Scramble"))
# t.test(value~name, data=values.both)

## Generate vectors for each group
values.scramble <- test_data %>% filter(name =="Scramble") %>% pull("value")
values.siRNA1 <- test_data %>% filter(name =="siRNA1") %>% pull("value")

## t.test
t.test(values.scramble,values.siRNA1)

## pairwise comparisons of all groups
pairwise_test<- compare_means(value~name, data=test_data, method="t.test")

```

```{r tTestTable, echo=F}

pairwise_test[,2:6]%>% kbl(digit=3, caption = "Results from pairwise_test") %>% kable_classic(full_width = F, html_font = "Cambria", font_size=16)

```

The are many pairwise tests that are not relevant to the null hypothesis and only increase multiple testing. We are interest if the knockdown of geneX alter cell proliferation, therefore we can test the response of cells treated with siRNA versus the appropriate control (in this case scramble control). 
The reagent control can be excluded for now.

```{r t.testMultiple}
## Select the nomalised data and remove the cellsOnly and Reagents data, limit to AN3CAs only.
# Scramble vs each siRNA
test_data<- KD_data %>% `[[`('normalised') %>% pivot_longer(1:6) %>% filter(name != "CellsOnly", cellLine == "AN3CA", name != "Reagents") 

pairwise_test<- compare_means(value~name, data=test_data, method="t.test", ref.group = 'Scramble')
```

```{r tTestTable2, echo=F}
pairwise_test[,c(2:6,8)]%>% kbl(digit=3, caption = "Results from pairwise_test-siRNA compared to scramble control") %>% kable_classic(full_width = F, html_font = "Cambria", font_size=16)
```

Although a one-way ANOVA may be considered, there is an issue with the independence of each siRNA. Each siRNA does target the same gene and should have similar biological effect.

<br>

# ANOVA

In the case were there are multiple experimental groups, pairwise t-test are inappopriate as the error rate quickly increases. In these cases controling for multiple comparisons need to be considered. Analysis of variance (ANOVA), is the term for a collection of methods used to estimate significance between group means. The error rate is reduced because the error is calculated for the whole set of comparisons, not pairwise as would be for a t-test.

Similar to a t-test, an ANOVA looks to reject the null hypothesis that there is no difference between group means ($H_0: \mu_1 = \mu_2 = \mu_3   = ... = \mu_n$). Therefore, an ANOVA can say there is a difference between at least two groups but does not tell which groups are different.

**Assumptions of ANOVA**

<ol class="matched">
<li>**Independence of observations**: There are no hidden relationships among observations. </li>
<li>**Normally-distributed response variable**: The values of the dependent variable follow a normal distribution.</li>
<ul style="font-size:0.9em">
  <li> Although ANOVA does assume that the data is normally distributed, it does tolerant violations well. However, the Kruskal-Wallis H test might be more appopriate for data that violates normality.</li>
</ul>
<li> **Homogeneity of variance**: The variation within each group being compared is similar for every group.</li>
<ul style="font-size:0.9em">
  <li>This can be tested with test for homogeneity of variance (e.g. Levene's, Bartlett's or Brown-Forsythe tests)</li>
</ul>
</ol>

### Reference

[University Alberta - Presentation on ANOVA assumptions](https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/slides_-_anova_assumptions.pdf)


## One-way ANOVA
To look at how to do this in R, lets use the inbuilt dataset `chickwts` which has the weight of chicks on different feeds.

```{r one-wayano, comment=NA}
# anova using the formula syntax
a1 <-aov(weight ~ feed,data = chickwts)
summary(a1)
```


The ANOVA output provides an estimate of how much of the variation in weight (depedent variable) can be explained by the feed (independent variable). The summary describes the degree's of freedom ($\text{df}_1=n-1$), the F-value which is a measure of $\frac{\text{between group variation}}{\text{within group variation}}$ and the p-value. In this case, the null hypothesis is rejected and chick weight significantly differs according to feed type ($\text{f}(5)=15.37, p<0.001$).


```{r bp2, echo=F, fig.height=3, fig.width=5, fig.cap="Significant difference (ANOVA) in chick weights and six week diet on various feed supplement.", fig.align='center'}
bxplot(chickwts, aes(x=feed, y=weight)) + stat_compare_means(method='anova', size=3.5, label.y = 415) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + xlab(NULL) + ylab("weight (g)")
```


## Post Hoc Analysis
If an ANOVA fails to reject the null (e.g. p > 0.05), then there is no statistical significances between group means. If the null is rejected, then it is often of interest to identify which particular group means were statistical different. This is were post-hoc test are performed, there are several methods that will not only tell you which comparisons are significant but always adjust for error rates (type I error rate).  

### Tukey's method
This method is used to test whether the difference between means are non-zero. Tukey's is one of the most commonly used methods to adjust for multiple comparisons. This method simply determines whether the difference in pairwise means is non-zero (i.e. $\bar{x}_{group1}-\bar{x}_{group2} \neq 0$). To do this, a confidence interval is calculated for each pairwise difference, if these confidence interval do not overlap 0 then the null hypothesis can be rejected.

In `R` there are many ways to do both ANOVA and Tukey's post-hoc tests (also called "Tukey Honest Significant Differences"). My preference is the `tukey_hsd()` function from `rstatix`, solely due to the output be ammendable to label plots. The `tukeyHSD()` funciton in the base `stats` package will give identical results, just the output will be in a different structure.

```{r TukeysCode, eval=F, warning=F}
## tukey_hsd function from rstatix
stat.test<-aov(weight ~ feed,data = chickwts) %>% tukey_hsd()
```

```{r Tukeys,  fig.align='center', fig.height=4, echo=F, warning=F, fig.cap="Tukey's multiple comparisons. A) Difference between pairwise comparison with 95% CI. B) The effect of feed on chick weight. Statistical analysis by one-way ANOVA with Tukey's post-hoc test. * p < 0.5, ** p < 0.001, p < 0.0001 "}
stat.test<-aov(weight ~ feed,data = chickwts) %>% tukey_hsd()

stat.test2 <- stat.test[stat.test$p.adj.signif != "ns",]
stat.test3 <- stat.test
stat.test3$comparison <- paste(stat.test3$group1, stat.test3$group2,sep="-")
p0 <-ggplot(stat.test3, aes(x=comparison, y=estimate)) + geom_point() +coord_flip() +theme_bw(base_size = 12) + geom_errorbar(aes(ymin=conf.low, ymax=conf.high)) +theme(axis.title.y = element_blank()) + geom_hline(yintercept = 0, linetype=2, colour ='red')+
  theme(plot.margin=unit(c(12.5,5.5,5.5,5.5),"points"))

p1 <- bxplot(chickwts, aes(x=feed, y=weight))  +
  stat_pvalue_manual(stat.test2, label = "p.adj.signif", hide.ns = T, y.position =
                                    max(chickwts$weight)*seq(1.1, 1.8,0.1)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +xlab(NULL)

plot_grid(p0,p1, ncol=2,  align = "h", axis = "b", labels = "AUTO")
```

### Dunnett's Method
This method should be used to compare multiple to groups to control (reference) group. As an example, lets generate some data and a hypothetical question of interest. Say that we are interested in a range of new drug that improves haemoglobin levels in anemic individuals and compare that to standard care. For this, the hypotheical data will be the percentage increase above baseline for each individual. 

```{r Dunnetts}
## Make some data
set.seed(123)
low <- rnorm(1000, mean= 95, sd =2.5)
med <- rnorm(1000, mean= 125, sd =5)
high <- rnorm(1000, mean= 150, sd =9)
score = c(sample(med, 8, replace = T),sample(high, 2, replace = T),
          sample(low, 9, replace = T),sample(med, 1, replace = T),
          sample(low, 4, replace = T),sample(med, 6, replace = T),
          sample(med, 1, replace = T),sample(high, 9, replace = T),
          sample(med, 7, replace = T),sample(high, 3, replace = T),
          sample(low, 3, replace = T),sample(low, 7, replace = T),
          sample(high, 7, replace = T),sample(med, 3, replace = T))
dunnetts <- data.frame(Technique = as.factor(rep(c("Existing", "drugA", "drugB","drugC", "drugD","drugE","drugF"), each = 10)),
                       Score = score)

summary(aov(Score ~ Technique, data = dunnetts))
stat.test<-DunnettTest(Score ~ Technique, data = dunnetts,control = "Existing")
stat.test

```

```{r dunnetBxplot, echo=F,  fig.width=6, fig.height=3, fig.cap="Effect of treatment on blood haemoglobin in amenic individuals. Statistical analysis by one-way ANOVA with Dunnett post-hoc test. * p < 0.5, ** p < 0.01, p < 0.001"}
stat.test2 <- as.data.frame(stat.test$Existing)
stat.test2$group1 <- as.factor(unlist(lapply(strsplit(rownames(stat.test$Existing),"-"), function(i) i[1])))
stat.test2$group2 <- as.factor(unlist(lapply(strsplit(rownames(stat.test$Existing),"-"), function(i) i[2])))
stat.test2$p.format <- round(stat.test2$pval, 3)
stat.test2$p.signif <- p.siginf(stat.test2$pval)
dunnetts$Technique <- as.factor(dunnetts$Technique)

dunnetts %>% bxplot(aes(x=fct_inorder(Technique), y=Score)) + 
  stat_pvalue_manual(stat.test2,label = "p.signif", hide.ns = T, y.position = c(max(dunnetts$Score*1.02),max(dunnetts$Score*1.05),max(dunnetts$Score*1.08),max(dunnetts$Score*1.11))) + 
  ylab(expression("Increase in blood \nhaemoglobin (%)")) +xlab(NULL) +
  theme(plot.margin=unit(c(5.5,5.5,5.5,18.5),"points"))
```

<hr>
# Custom code
A ggplot function that changes some parameters that were universal to boxplots used throughout
<a id="bxplot_code"></a>
```{r bxplot_function, eval=FALSE}
bxplot <- function(...){ggplot(...)+geom_boxplot(width=0.3, size=1, fatten=1, colour="grey70") +
  geom_point(colour="steelblue", size=1.2, alpha=0.5) +
  theme_bw(base_size=12)}
```