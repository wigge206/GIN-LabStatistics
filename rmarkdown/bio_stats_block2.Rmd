---
title: "2x2 Tables and Chi-Squared tests"
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    number_sections: false
    theme: lumen
    css: www/css/master.css
    highlight: default
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, fig.align = 'center')
```


```{r datasets, results='hide',error=FALSE, warning=FALSE, message=FALSE,echo=F}
## Read excelsheets
library(openxlsx)

## Packages used for 'data wrangling'
library(tidyverse)
library(data.table)

## Extra stats package
library(rstatix) ## used to help format stats into dfs for ggplot
library(DescTools) ## For Dunnett's test
library(epitools)
library(epiR)
library(mlbench)
library(pROC) ## For ROC curves

## Packages for plotting and table outputs
library(ggplot2)
library(ggsci)
library(ggpubr)
library(ggrepel)
library(cowplot)
library(kableExtra) ## used for to make nicer looking tables
```


```{r global_functions, echo=FALSE}
bxplot <- function(...){ggplot(...)+geom_boxplot(width=0.4, size=1, fatten=1, colour="grey70") +
  geom_point(colour="steelblue", size=1.2, alpha=0.5) +
  theme_bw(base_size=14)}

p.siginf<- function(vec){
  out<-c()
  for(i in 1:length(vec)){
    if(vec[i] < 0.001){
      out <- c(out, "***")
    }else if( vec[i] < 0.01){
      out <- c(out, "**")
    } else if(vec[i] <0.05){
      out <- c(out, "*")
    }else{
      out <- c(out, "ns")
    }
  }     
  return(out)
}
```

# Categorical data analysis

For categorical data, there is an evaluation of the proportions of data rather than summaries such as means or medians. A contingency table can be used to display frequencies of events for two given categorical variables and can aid in determining probabilities of events. 


```{r 2x2, echo=F}
data.frame(C1=rep('Exposure',3), C2 = c("Yes","No", "Totals"), plus=c('A', 'C', "A+C"), minus=c('B', 'D',"C+D"), Totals = c("A+B", "C+D", "N")) %>%
  kbl(col.names=c("","", "Yes","No", "Totals"), caption = "2x2 contingency table",align = 'c', table.attr =  'style= "width: 35%;"') %>% 
  kable_classic(html_font = "Cambria", font_size=16) %>% 
  collapse_rows(columns=1) %>% add_header_above(c("","", "Outcome" =2, "")) 
```

Similarly, we can used a 2x2 table to inspect the accuracy of a dignostic test. By compared the stratifiying negative and positive test by true disease state we can caluclate the specificly the senseitvity, specifcity, positive predictive (PPV) and negative predictive values (NPV).


```{r 2x2di, echo=F}
data.frame(C1=rep('Test',3), C2 = c("Yes","No", "Totals"), plus=c('True Positive', 'False Negative', "Number with disease"), minus=c('False Positives', 'True negatives',"Number without disease"), Totals = c("Number who test positive", "Number who test negative", "N")) %>%
  kbl(col.names=c("","", "Yes","No", "Totals"), caption = "2x2 contingency table",align = 'c', table.attr =  'style= "line-height:3ch;"') %>% 
  kable_classic(html_font = "Cambria", font_size=16) %>% 
  collapse_rows(columns=1) %>% add_header_above(c("","", "Disease" =2, "")) %>% footnote(c("Sensitivity = TP/(TP+FN),   Specificity=TN/(FP+TN)", "Positive Predicitve Value=TP/(TP+FP),  Negative Predictive Value=TN/(TN+FN)"), general_title ="" )
```

Sensitivy is how accurate the test was at identify a true case. The specificity is how good the test was at correctly identifying those without disease. The PPV is how good the test is at the test is at identifying case (e.g. if a positive test, how likely is that person to have disease). Similarly, the NPV is how good a test is at ruling out disease (e.g. if a negative test, how likely is it to no have truely have disease.)



As example, we can look at the effects of mothers smoking on delviery of babies under 2.5 kg (low birth weights). In the `birthwt` dataset there is a caterogical terms for birth wight less than 2.5 kg (`low`) and smoking status during pregnancy (`smoke`).

```{r}
bwt <- MASS::birthwt # load data
bwt.cont<- table(bwt$smoke, bwt$low, dnn =c("Smoke", "Low BW")) # frquency of events 0=no, 1=yes

## the epiR functions require a particular order (e.g. first column is outcome positive, first row is expsoure positive)
bwt.cont <- bwt.cont[2:1,2:1]
```

```{r bwt2by2, echo=F}
data.frame(C1=rep('Smoking',2), C2 = c("Yes","No"), plus=c('30', '29'), minus=c('44', '86')) %>%
kbl(col.names=c("","", "Yes", "No"),caption = "Frequency of low birth weight and mother smoking status",align = 'c', table.attr =  'style= "width: 45%;"') %>%
    kable_classic(html_font = "Cambria", font_size=16) %>% 
  collapse_rows(columns=1) %>% add_header_above(c("","", "Low birth weight (<2.5kg)" =2)) 

```

The odd of having low birth rate give a mother smoked during pregnancy can be easily calculated as 
<hr>
$$\begin{gather*}
\frac{\text{Odds of baby with a low birth weight was exposed to a mother smoking}}{\text{Odds that a baby born with healthy birth weight was exposed to a mother smoking}}\\
 \frac{A/C}{B/D} = \frac{30/86}{44/29} = 2.02
\end{gather*}$$
<hr>
Therefore, the odds of having a low birth weight child for a smokers is 2.02 times greater than the odds of having a low birth weight child for non-smokers. To add more information it is important to determine the confidence intervals and significances. These, and the odd ratios, can be calculated using functions built in to `r`. However, `epiR` and `epitools` are two commonly used packages that make this epidemiological type analysis easier.
Each packages requires the data to be in a specific format, therefore get the references for each packages. For `epiR`, the funciton `epi.2by2()` needs a two-by-two table with the first column as of outcome positive and first row as expsoure positive (Table \@ref(tab:2x2))

```{r oddsRatio}
epi.2by2(dat = bwt.cont, method="cohort.count", conf.level = .95)
```

# Chi-squared test
The Chi-square test of independence is used to determine whether there is a significant relationship between two categorical variables. The Chi-squared test compares the observed frequencies of events to the expected frequencies (under the assumption of no relationship between variables). 

Taken the example above of birth weight and smoking in pregnancy (Table \@ref(tab:bwt2by2)), we can use the probabilities of each event occuring to calculate the expected events. For example, the probability that a women smoked during pregnancy is 0.392 (74/189) and the probability of a child being born of low birth weight is 0.312 (59/189). Under the assumption that the variables are indpedent, we can multiple these two probabilities and work the expected number of childern born at low weight given a mother that smoked as $0.392 \times 0.312 \times n$. For our dataset of 189 individuals this ~23 event (Table \@ref(tab:expected)).

```{r, expected, echo=F}
data.frame(C1=rep('Smoking',2), C2 = c("Yes","Yes","No","No"), C3 = c("Obs","Exp", "Obs","Exp"), plus=c('30', '23.10', '29', '35.90'), minus=c('44','50.90', '86','79.10')) %>% kbl(col.names=c("","","", "Yes", "No"),caption = "Frequency of observed and exprected child born with low birth weight and smoking status of the mother",align = 'c', table.attr =  'style= "width: 60%;line-height: 3ch;"') %>%  kable_classic(html_font = "Cambria", font_size=16) %>% 
  collapse_rows(columns=1:2) %>% add_header_above(c("","","", "Low birth weight (<2.5kg)" =2))
```

It is important to look at the expected events as if the occurance is less than 5 for any event than Chi-squared test are not recommended. 

Given the expected values, we can now estimate the Chi-squared statistics.

**Manually**  

$$\begin{gather*}
\chi^2=\sum{\frac{(O-E)^2}{E}} \\
\chi^2=\frac{(O-E)^2}{E} + \frac{(O-E)^2}{E} + \frac{(O-E)^2}{E} + \frac{(O-E)^2}{E} \\
\chi^2=\frac{(30-23.10)^2}{23.10} + \frac{(29-35.90)^2}{35.90} + \frac{(44-50.90)^2}{50.90} + \frac{(86-79.10)^2}{79.10} \\
\end{gather*}$$
Where $\chi^2$ is the test statistic and $O$ and $E$ are the observed and expected frequencies, respectively. The degrees of freedom is calculated by $(r-1)(c-1)$ where r and c are the number levels for each variable, respectively. In this case the degress of freedom are 1, (2-1)(2-1).

**With R**  

Instead of manually calculating all these terms `r` has a built in `chisq.test()` funciton, and the previosuly used `epi.2by2()` function will also calculate this.

```{r chisq}
chisq.test(bwt.cont, correct = F)
## Too inspect the expected values
chisq.test(bwt.cont, correct = F)$expected
```



# Receiver operating characteristic (ROC) 
ROC curves are a simiply way to inspect the relationship between sensitivity and specificity for every possible cut-off for a test/model etc. The area under the curve (AUC) can help be used to easily compare multiple ROC curves (e.g. different tests or models).

To illustrate how ROC curve summarise the sensitivity & specificity take Figure \@ref(fig:ROCproBNT)A, the red line is the given cut-off (threshold) for the test (e.g. individuals above the line would return a positive result). The two-by-two tables for each corresponding threshold can be seen in Table \@ref(tab:ROCproBNT2x2). The ROC curve line correspnds to the each changing senstivity and specificity as the threshold changes. 

```{r ROCproBNT, fig.cap=""}
## Load data important to detect dates
dat = read.xlsx("../Data/proBNP.xlsx", sheet = 1, detectDates = T)
## Calculate age (round-down to nearest year). -- Date.ofBirth wasn't detected as a date on import
dat$Age <- as.numeric(floor((dat$Baseline_Date - as.Date(dat$Date.of.Birth, "%d/%m/%Y")) /365.25))

## filter out missing data
# unsure what -1 is...
dat = dat %>% filter(EDNTpBNP > -1 & !is.na(GSDia1HF_New_At))

t.size = 8

p1<-ggplot(dat, aes(x=GSDia1HF_New_At, y= EDNTpBNP )) + geom_point() + geom_hline(yintercept = 10090, color='red') + theme_bw() + xlab("HF") + 
  ggtitle("Threshold = 10000")+ theme(plot.title = element_text(size = t.size))
p2<-ggplot(dat, aes(x=GSDia1HF_New_At, y= EDNTpBNP )) + geom_point() + geom_hline(yintercept = 5920, color= 'red') +theme_bw()+ xlab("HF")+ 
  ggtitle("Threshold = 5900")+ theme(plot.title = element_text(size = t.size))
p3<-ggplot(dat, aes(x=GSDia1HF_New_At, y= EDNTpBNP )) + geom_point() + geom_hline(yintercept = 4280, color= 'red') +theme_bw()+ xlab("HF")+ 
  ggtitle("Threshold = 4280")+ theme(plot.title = element_text(size = t.size))
p4<-ggplot(dat, aes(x=GSDia1HF_New_At, y= EDNTpBNP )) + geom_point() + geom_hline(yintercept = 1926, color= 'red') +theme_bw()+ xlab("HF")+ 
  ggtitle("Threshold = 1900")+ theme(plot.title = element_text(size = t.size))

roc1=roc(dat$GSDia1HF_New_At, dat$EDNTpBNP)
youden= coords(roc1, best.method = "youden", 'best') %>% mutate(label=paste(round(threshold,3), " (", round(specificity,3), ", ", round(sensitivity,3), ")", sep=""))
p5<-ggroc(roc1, size=1) + theme_bw() +
  geom_point(data=youden, aes(x=specificity, y=sensitivity), size=3) + 
  geom_text(data=youden, aes(x=specificity, y=sensitivity, label = label), nudge_x= .15, nudge_y = -.025)

top <- plot_grid(p1,p2,p3,p4, nrow=1)
plot_grid(top, p5, nrow=2, rel_heights = c(1,1.5), labels=LETTERS[1:2])
```



```{r ROCproBNT2, echo=F, results='asis',  message=F, comment=F, warning=F, fig.cap=""}

dat$GSDia1HF_New_At <- factor(dat$GSDia1HF_New_At, levels =c("Y","N"))

threshold = c(10090, 5920,4280,1926)
title = "Threshold at"
pos=c('float_left', "float_left", "float_right", 'float_right')
lst=list()
for(i in 1:4){
  lst[[i]] = as.data.frame.matrix(table(dat$GSDia1HF_New_At, dat$EDNTpBNP < threshold[i])) %>% rownames_to_column()%>% 
  add_column(c("HF","HF"),.before="rowname") %>% kbl(col.names=c("","","Y","N"), table.attr =  'style= "width: 23%;"') %>% 
  kable_classic(html_font = "Cambria", font_size=14, position=pos[i],full_width=T) %>% 
  collapse_rows(columns=1) %>% add_header_above(c("", "","proBNP"=2)) 
}

print(lst[[1]] %>% add_header_above(c("Threshold cutoff= 10090"=4)))
print(lst[[2]]%>% add_header_above(c("Threshold cutoff= 5920"=4)))
print(lst[[3]]%>% add_header_above(c("Threshold cutoff= 4280"=4)))
print(lst[[4]]%>% add_header_above(c("Threshold cutoff= 1926"=4)))

```

<div style="clear: both;"></div>


We can compare how well the test is at different age groups 

```{r proBNPage, echo=F}
roc2<-roc(dat$"GSDia1HF_New_At"[dat$Age < 60],dat$"EDNTpBNP"[dat$Age < 60])
roc3<-roc(dat$"GSDia1HF_New_At"[dat$Age > 61],dat$"EDNTpBNP"[dat$Age > 61])
youden2 = coords(roc2, best.method = "youden", 'best') %>% mutate(label=paste(round(threshold,3), " (", round(specificity,3), ", ", round(sensitivity,3), ")", sep=""))
youden3 = coords(roc3, best.method = "youden", 'best') %>% mutate(label=paste(round(threshold,3), " (", round(specificity,3), ", ", round(sensitivity,3), ")", sep=""))
youden2 = rbind(youden2,youden3)
youden2$AUC = paste(c("< 60","> 60"),"AUC ", c(round(auc(roc2),3),round(auc(roc3),3)))
youden2$name = c('x','y') 
youden2$AUC.x = .15
youden2$AUC.y = c(.05,.1)

ggroc(list(x=roc2,y=roc3)) + theme_bw() + geom_point(data=youden2, aes(x=specificity, y=sensitivity), size=3) + 
          geom_text(data=youden2, aes(x=specificity, y=sensitivity, label = label), nudge_x= .15, nudge_y = -.025) +
  geom_text(data=youden2, aes(x=AUC.x, y=AUC.y, label = AUC)) +theme(legend.position = 'none') +scale_color_manual(values=c('red','black'))


```

```{r ROC, out.width="100%", fig.cap="ROC curve comparing two markers to predict..."}
dat <- read.xlsx("../Data/ROCdata.xlsx") # only one sheet no need to specify

rocA=roc(dat$Death.at.1.yr,dat$Marker.A)
rocB=roc(dat$Death.at.1.yr,dat$Marker.B)

par(mfrow=c(1,2), mar=c(4,4,.1,.1), pty='s')
plot(rocA)
lines(rocB, col='red')
text(0.3,.2,paste("Marker A: AUC", round(auc(rocA),3)), cex=.8)
text(0.3,.125,paste("Marker B: AUC", round(auc(rocB),3)), col='red', cex=.8)

plot(rocA,print.thres="best", print.thres.best.method="youden", legacy.axes = TRUE, print.thres.adj=c(.85,-1.25), print.thres.cex=.7, pty='s')
plot(rocB,print.thres="best", print.thres.best.method="youden", print.thres.col='red',  add=T, col='red', legacy.axes = TRUE, title= "Threshold for best model (Youden's method)", print.thres.cex=.7, pty='s')

```



# Logistic Regression

Logistic regression is a method used to model binary outcomes. In R logistic regression is a generalised linear model and can be implemented with the `glm()` function. The `glm()` funciton has many types of models, to use logistic regression the `family` options should be set to `'binomial'` (e.g. `glm(response variable ~ predictor variables,family='binomial', data=df)`). 

```{r}
data("PimaIndiansDiabetes2")
Diabetes<- na.omit(PimaIndiansDiabetes2) # remove missing data
#levels(Diabetes$diabetes) <- 0:1 # relabel neg and pos to 0 and 1

## Fitting logistic regression predicted by all variables 
model1 <- glm (diabetes~., data=Diabetes, family = 'binomial')
## not the period tells R to use all columns other than diabetes. This is the same as
##  glm(diabetes ~ pregnant + glucose + pressure + triceps + insulin + mass + pedigree + age ,data=Diabetes, family = 'binomial')

summary(model1)
```

The summary depicts the estimate weight each term has on the prediction of diabetes. For example, with every increase unit increase of glucose will increase the log odds of diabetes by 0.036. 

